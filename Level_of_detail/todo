
TODO AND OTHER:

// Iteration 1:
1. Redo selector class using property maps.
2. For now I use built in conditions inside selection strategy classes. Change it to any custom condition later.
3. Refactor the preprocessor class.
4. Update Level_of_detail_loader.h - currently it is fixed temporary implementation.
5. For LOD I can stick to my own simple data structures. For some packages like 2D structuring I can already mimic CGAL general style. In general, first make it work with simple data structures and then fix API.
6. It is important to gradually increase the complexity of the input data set and see if our package handles it well.
7. It is maybe helpful to work building by building and create an oriented bounding box around each building, which can become the building's boundary in the worst case.
8. Too long walls come from shape detection package if the cluster_epsilon parameter is choosen to be too large.
9. Some walls are missing due to the precision problems when creating segments (projection of a point onto a line).
10. I reject all planes that have an angle more than 10 degrees with respect to the closest vertical plane. This allows to solve some of the missclassification problems.
11. Should I enforce the same normals for the regularized plane?
12. Improve the function for getting corners. Use a function to detect all cycles in the undirected graph obtained in the function create_structured_adjacency().
13. Method for adjacency / corners is not robust when wrong planes are detected by the RANSAC. In this case, it may happen that lines that we intersect to get corners produce points which are far away from the real data set.
14. Maybe better to pass all indices except for building boundaries to the visibility class instead of the whole input container?
15. Add one more label to the input: 1 detected as planar, 0 detected as something else. Then add a selector class to selecte points, which are detected as something else and are facade points that is building boundary. Add these points to the final structured set of points with the label CLUTTER.
16. Actuually my reconstruction code should compute the cost function for each surface S in all graph cut iterations.


// Iteration 2:
1. What about creating new semantic data structures such as "Building", "Tree", "Car" and so on?
2. Can I make an existing edge constrained? What if I have one building inside another one. How can I detect/correct after the graph cut that interior building's walls should be constrained?
3. How to get an edge if I know face handle and its neighbouring face handle?
4. Maybe remove CDT from height fitters?
5. Add a new outliner algorithm that will work with multiple boundaries - for example one exterior boundary and one interior boundary.
6. How to get the n-th face iterator: like std::distance(faces.begin(), n)?
7. How to get indices of the faces, vertices from the iterators when saving them in .ply or any other format?
8. Is it possible to add colors to faces in the Polyhedron_incremental_builder class?
9. How to create a 2-manifold or watertight mesh from the polygonal soup, which is LOD1 now?
10. Add classification labels to Level_of_detail_enum.h.
11. Some buildings turn out to be just a triangle that is why some walls of the buildings have different colours.


// Iteration 3:
1. Classification package saves some points with label -1. So it is not guaranteed that all points are classified? Why?
2. Fix bug or whatever it is in the outliner class such that it does not create any inverted faces as now - it may be a Meshlab bug.
3. Remove lonely triangles in the buildings finder by creating a set of constrained edges between in and out after the final graph cut. It may also help in fixing 2. above.
4. The main problem with real data comes from creating corners. In this case, I have to intersect segments or their supporting lines, which creates many points at infinity.
5. In demo classification, radius label changed its position. Actually sometimes radius label is not saved at all. Sometimes, it is added at the end like in the paris data set, and sometimes after nz as in the p10 data set.
6. When cliking anywhere away from the classification pop-in window, the focus disappears and we have to start all over again.
7. p10 data set has the same point twice after running region growing.
8. Segmentation fault when loading the p10 class_trial.ply and changing points+normals to the next mode in the master/Polyhedron_demo.
9. Outliner algorithm is very sensitive to noise and incorrect input data! Weak link. Second weak link is intersection between structured segments and fitting lines to the input data coming from shape detection.
10. Might be a bug in the graph cut since after applying it in the short pipeline I have many tiny triangles, which are in and next to them other tiny triangles, which are out?
11. Short pipeline is easier to set up, requires fewer parameters, much slower to run and its robustness depends directly on the classification result. It is also senstive to the boundaries (wether to compute them or not in the outliner).


// Iteration 4:
1. Natural neighbour function bugs for some sample points and I cannot handle this execption. The bug is due to the insufficient number of points in Delaunay triangulation or because some of its vertices coincide with sample points.
2. Try affine coordinates instead of natural neighbour coordinates in the visibility module.
3. Maybe better to use sphere neighbour search instead of knn in thinning?
4. Natural neighbours approach is very inefficient because we need to build Delaunay triangulation for input data set with thousands of points.
5. Natural neighbour visibility is not very robust because it depends on random sampling of each triangle.
6. I think the main problem with graph cut for the pipeline without shape detection comes from the fact that all edges are free-form coherent and are favoured more or less the same.
7. Parameters for the graph cut:

	a. m_alpha should always be greater or equal 1, though bigger than 1 does not make any difference - so just use 1.
	b. m_beta should be a big value >= 1, increasing it makes less inside triangles.
	c. m_gamma is not used in the clutter-based pipeline (without shape detection); for the structuring-based pipeline (with shape detection), just use some big value. Making it bigger or smaller does not change the result.

8. Thin triangles are not good for the point based visibility.
9. New updated code works much faster.
10. Is there a better way to get the intersected side of the face in the line walk without traversing all face edges?
11. Where I can find a paper about bands for ray shooting?


// Graph cut:
For clutter-based cdt all edges are free-form coherent - Yes.
Remove m_beta from out - Makes all triangles in!
Use squared length instead of length for edge weights - With squared length the result seems to be cut over the longer edge.
Change free_form_quality function to the fixed value or improve it - It looks ok, if I want the pure shortest path cut, use 1 instead of this function - at least for some data sets with some parameters, it works.
I do max flow between faces = graph nodes (favour big values) or min cut over the finite edges = graph edges (favour small values) - Yes.
Add an extra coherence to the free-form coherent edges using for example in and out data - Added tanh adapter to node values.


// Iteration 5:
1. Add after graph cut constrained edges between all in and out. All other constrained edges should be removed. In this case we will get a good LOD0 and LOD1. For LOD2 we save info with previously removed constrained edges and build different types of buildings, which are multilevel. Then we can take each building and work per building, split it into multi levels, add roofs, and so on.
2. Should we really change simple version of my unordered outliner to the pivoting one?
3. Should we really change my simple version of the banding in the ray shooting to the complex one of Pierre?
4. Should we really implement the watertight 2-manifold version of the LOD0 and LOD1?
5. Ray shooting - small edge criteria makes the results worse!
6. Why the first query point in knn search works so long? Sometimes I have segmentation fault on create_internal_node().
7. The barycentric method does not work with complex data set, I get the segmentation error in the tree data structure.
8. Should I assume that building that shares one vertical segment in 3D (or vertex in 2D) with the other building is its neighbour?
9. Make all edges in the unoriented boundary algorithm unique.
10. How should we avoid triangles in CDT that have nearly zero area?
11. The ray shooting should improve the case when we have adjacent buildings or multiple-level buildings.
12. Add exporter and estimator for parameters.
13. For ray shooting without constrained edges, we may need to check for each edge if it is clutter or not and then use really smart criteria to decide if we need to change sign or not, because if we do it wrong, we mess up visibility predicitions for a lot of triangles.

Points: finish and test visibility; finish and test outliner with lod0-lod1; finish and test all other small tasks - sphere search in thinning, bug in structuring, etc.; test everything and prepare the big Paris data set.


// Iteration 6:
1. Create a script that runs tests for all modules like base, buildings, clutter, etc.
2. After classifying and saving data set, if loading this saved data set without removing the previous one, its colours are changed to the default.
3. How to add constrained edges after the graph cut and split different neighbouring buildings in the pipeline version without shape detection?
4. Empty xyz files are not opening.
5. Fuzzy iso box does not work.

Ideas:
1. Fixed scale.
2. Get knn.
3. Consider standard point distributions (see paper).
4. Compute average spacing and remove dimension 0.
5. Compute coverage (or occupancy) and remove uniformly distributed cases of dimension 2.
6. Try minshift in normal periodic space to get clusters or
7. Apply spatial clustering using k means without normals (1 -> 5), compute error and decide when to stop based on the ratio (multiply or divide by the number of clusters, radius, etc.), remove unnecessary cases where we have multiple dense clusters.
8. Apply normal clustering using k means for lines (or points with normals, or vectors) (compute distance between two lines as an angle on the periodic circle) or the unity paper, or the k means++. You can use ideal rate for lines to check. Apply 1 -> 5 and stop when the error does not change. K means error either decreases or stay constant. For line the rate should stay constant.
9. Use clusters from 8 to fit lines (clusters depend on the chosen scale). When fitting lines you can use error from the fitter function to check the goodness of the fit and such variance of clusters and overall quality. There are two variances - between clusters and inside each cluster between points. When fitting line do not use only points but also normals (average them to find an average normal of the line and use the best point to create a line with this normal or correct the fitted line).

1. You can split buildings using roof information and alpha shapes.
2. Visualize each cluster and visualize result of the clustering for each set of knn.
3. Implement all cases with point distributions from the whiteboard.
4. Use robust pca to find normals for each set of knn locally in 2D without using 3D normals. Or if we have 3D normals use them, otherwise estimate normals locally in 2D.


// Iteration 7:
1. Can we use an average spacing instead of sparsity test with grid simplify when cheking for dimension 2? It seems to work better.
2. Fix in the grid simplify the boundary_data setting. Now I assign new indices, which may not correlate with original input. Since now, I use it only locally when creating cdt, it is not important, but if I want to access normals from original data using this mapping, I will introduce wrong data.
3. Try to make the region growing class constant.
4. As alternative, you can use free_form_quality function for all edges: free form, incoherent, and structure coherent.
5. How to use property maps with alpha shapes / triangulations? Accelerate my boundary extractor that is based on alpha shapes.
6. Randomness in region growing. Sometimes it gives 67 lines, sometimes 69. Is it ok?
7. Free form clutter is added everywhere and it makes cdt looking worse. In general, I try to avoid adding it.


// ----------------------------------------------------
// From now on see the folder extra in the logs folder!
// ----------------------------------------------------
